# ğŸ“‹ PLAN DE IMPLEMENTACIÃ“N - SEMANA 8
## VitalWatch con Apache Kafka - "Consumiendo Stream de datos"

**Fecha inicio:** Semana 8
**Experiencia:** 3 - Streaming con Kafka
**Puntos totales:** 100 puntos

---

## ğŸ¯ OBJETIVOS DE LA SEMANA 8

1. âœ… Migrar de RabbitMQ a Apache Kafka
2. âœ… Configurar cluster Kafka (3 nodos + 3 Zookeeper)
3. âœ… Crear 2 tÃ³picos de Kafka
4. âœ… Desarrollar 2 productores + 2 consumidores
5. âœ… Integrar con Oracle Cloud
6. âœ… Video de presentaciÃ³n (5-10 min)

---

## ğŸ—ï¸ ARQUITECTURA KAFKA - VITALWATCH

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CLUSTER KAFKA (Docker)                        â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Kafka 1     â”‚  â”‚  Kafka 2     â”‚  â”‚  Kafka 3     â”‚          â”‚
â”‚  â”‚  Port: 9092  â”‚  â”‚  Port: 9093  â”‚  â”‚  Port: 9094  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚         â–²                 â–²                 â–²                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ Zookeeper 1  â”‚  â”‚ Zookeeper 2  â”‚  â”‚ Zookeeper 3  â”‚          â”‚
â”‚  â”‚  Port: 2181  â”‚  â”‚  Port: 2182  â”‚  â”‚  Port: 2183  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚           Kafka UI (Port: 8080)                   â”‚           â”‚
â”‚  â”‚  - Ver tÃ³picos                                    â”‚           â”‚
â”‚  â”‚  - Monitorear mensajes                            â”‚           â”‚
â”‚  â”‚  - Ver consumidores activos                       â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TÃ“PICOS KAFKA                            â”‚
â”‚                                                                   â”‚
â”‚  ğŸ“Š signos-vitales-stream                                        â”‚
â”‚     â”œâ”€ Particiones: 3                                            â”‚
â”‚     â”œâ”€ Replication Factor: 2                                     â”‚
â”‚     â””â”€ Mensajes: Stream continuo de signos vitales              â”‚
â”‚                                                                   â”‚
â”‚  ğŸš¨ alertas-medicas                                              â”‚
â”‚     â”œâ”€ Particiones: 3                                            â”‚
â”‚     â”œâ”€ Replication Factor: 2                                     â”‚
â”‚     â””â”€ Mensajes: Alertas mÃ©dicas crÃ­ticas                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MICROSERVICIOS PRODUCTORES                    â”‚
â”‚                                                                   â”‚
â”‚  1ï¸âƒ£ PRODUCER: Vital Signs Stream Generator (Port: 8081)        â”‚
â”‚     â”œâ”€ FunciÃ³n: Generar signos vitales cada 1 segundo (CRON)   â”‚
â”‚     â”œâ”€ Publica a: signos-vitales-stream                         â”‚
â”‚     â”œâ”€ TecnologÃ­a: Spring Boot + Spring Kafka                   â”‚
â”‚     â””â”€ Endpoints: /api/v1/stream/start, /api/v1/stream/stop    â”‚
â”‚                                                                   â”‚
â”‚  2ï¸âƒ£ PRODUCER: Alert Processor (Port: 8082)                     â”‚
â”‚     â”œâ”€ FunciÃ³n: Procesar stream y detectar anomalÃ­as            â”‚
â”‚     â”œâ”€ Consume de: signos-vitales-stream                        â”‚
â”‚     â”œâ”€ Publica a: alertas-medicas                               â”‚
â”‚     â””â”€ LÃ³gica: Detecta valores crÃ­ticos en tiempo real          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MICROSERVICIOS CONSUMIDORES                   â”‚
â”‚                                                                   â”‚
â”‚  3ï¸âƒ£ CONSUMER: Database Saver                                   â”‚
â”‚     â”œâ”€ FunciÃ³n: Guardar datos en Oracle Cloud                   â”‚
â”‚     â”œâ”€ Consume de: signos-vitales-stream + alertas-medicas     â”‚
â”‚     â”œâ”€ Base de datos: Oracle Autonomous Database                â”‚
â”‚     â””â”€ Tablas: SIGNOS_VITALES_KAFKA, ALERTAS_KAFKA             â”‚
â”‚                                                                   â”‚
â”‚  4ï¸âƒ£ CONSUMER: Summary Generator                                â”‚
â”‚     â”œâ”€ FunciÃ³n: Generar resÃºmenes diarios                       â”‚
â”‚     â”œâ”€ Consume de: ambos tÃ³picos                                â”‚
â”‚     â”œâ”€ Almacena: EstadÃ­sticas agregadas                         â”‚
â”‚     â””â”€ Tabla: RESUMEN_DIARIO_KAFKA                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ ESTRUCTURA DEL PROYECTO

```
vitalwatch-kafka/
â”‚
â”œâ”€â”€ docker-compose-kafka.yml              # â­ NUEVO: Cluster Kafka completo
â”‚
â”œâ”€â”€ kafka-config/                         # â­ NUEVO: Configuraciones Kafka
â”‚   â”œâ”€â”€ server-1.properties
â”‚   â”œâ”€â”€ server-2.properties
â”‚   â”œâ”€â”€ server-3.properties
â”‚   â””â”€â”€ zookeeper.properties
â”‚
â”œâ”€â”€ producer-vital-signs-stream/          # â­ NUEVO: Productor 1
â”‚   â”œâ”€â”€ src/main/java/.../
â”‚   â”‚   â”œâ”€â”€ producer/StreamProducer.java
â”‚   â”‚   â”œâ”€â”€ scheduler/VitalSignsScheduler.java  (CRON cada 1 seg)
â”‚   â”‚   â”œâ”€â”€ model/VitalSignsMessage.java
â”‚   â”‚   â””â”€â”€ config/KafkaProducerConfig.java
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ producer-alert-processor/             # â­ NUEVO: Productor 2 (tambiÃ©n consume)
â”‚   â”œâ”€â”€ src/main/java/.../
â”‚   â”‚   â”œâ”€â”€ consumer/VitalSignsConsumer.java
â”‚   â”‚   â”œâ”€â”€ processor/AlertProcessor.java
â”‚   â”‚   â”œâ”€â”€ producer/AlertProducer.java
â”‚   â”‚   â””â”€â”€ config/KafkaConfig.java
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ consumer-database-saver/              # â­ NUEVO: Consumidor 1
â”‚   â”œâ”€â”€ src/main/java/.../
â”‚   â”‚   â”œâ”€â”€ consumer/MultiTopicConsumer.java
â”‚   â”‚   â”œâ”€â”€ service/DatabaseService.java
â”‚   â”‚   â”œâ”€â”€ repository/SignosVitalesKafkaRepo.java
â”‚   â”‚   â””â”€â”€ model/SignosVitalesKafka.java
â”‚   â”œâ”€â”€ wallet/                           # Oracle Wallet
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ consumer-summary-generator/           # â­ NUEVO: Consumidor 2
â”‚   â”œâ”€â”€ src/main/java/.../
â”‚   â”‚   â”œâ”€â”€ consumer/SummaryConsumer.java
â”‚   â”‚   â”œâ”€â”€ service/SummaryService.java
â”‚   â”‚   â””â”€â”€ model/ResumenDiario.java
â”‚   â”œâ”€â”€ pom.xml
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ create_tables_kafka.sql           # â­ NUEVO: Tablas para Kafka
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARQUITECTURA_KAFKA.md             # â­ NUEVO
â”‚   â”œâ”€â”€ GUIA_KAFKA.md                     # â­ NUEVO
â”‚   â””â”€â”€ postman-collection-kafka.json     # â­ NUEVO
â”‚
â””â”€â”€ PLAN_KAFKA_SEMANA8.md                 # Este archivo
```

---

## ğŸ“ TAREAS DETALLADAS

### âœ… TAREA 1: Configurar Cluster Kafka (20 puntos)

**Subtareas:**

- [ ] **1.1** Crear `docker-compose-kafka.yml` con:
  - 3 contenedores Kafka (brokers)
  - 3 contenedores Zookeeper
  - 1 contenedor Kafka UI
  - Networking entre contenedores

- [ ] **1.2** Configurar variables de entorno:
  ```yaml
  KAFKA_BROKER_ID: 1, 2, 3
  KAFKA_ZOOKEEPER_CONNECT: zookeeper1:2181,zookeeper2:2182,zookeeper3:2183
  KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
  KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka1:9092
  ```

- [ ] **1.3** Configurar Kafka UI:
  ```yaml
  KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka1:9092,kafka2:9093,kafka3:9094
  ```

- [ ] **1.4** Probar el cluster:
  ```bash
  docker-compose -f docker-compose-kafka.yml up -d
  docker ps  # Verificar 7 contenedores corriendo
  ```

**Entregable:** Cluster Kafka funcionando con 7 contenedores activos

---

### âœ… TAREA 2: Crear TÃ³picos en Kafka (20 puntos)

- [ ] **2.1** Crear tÃ³pico `signos-vitales-stream`:
  ```bash
  docker exec -it kafka1 kafka-topics.sh --create \
    --topic signos-vitales-stream \
    --bootstrap-server localhost:9092 \
    --partitions 3 \
    --replication-factor 2
  ```

- [ ] **2.2** Crear tÃ³pico `alertas-medicas`:
  ```bash
  docker exec -it kafka1 kafka-topics.sh --create \
    --topic alertas-medicas \
    --bootstrap-server localhost:9092 \
    --partitions 3 \
    --replication-factor 2
  ```

- [ ] **2.3** Verificar tÃ³picos creados:
  ```bash
  docker exec -it kafka1 kafka-topics.sh --list \
    --bootstrap-server localhost:9092
  ```

- [ ] **2.4** Ver en Kafka UI: http://localhost:8080

**Entregable:** 2 tÃ³picos creados y visibles en Kafka UI

---

### âœ… TAREA 3: Desarrollar Productor 1 - Stream Generator (20 puntos)

**DescripciÃ³n:** Microservicio que genera signos vitales simulados cada 1 segundo

**Archivos a crear:**

- [ ] **3.1** `VitalSignsScheduler.java`:
  ```java
  @Scheduled(fixedRate = 1000) // Cada 1 segundo
  public void generateVitalSigns() {
      VitalSignsMessage message = generateRandomVitalSigns();
      kafkaTemplate.send("signos-vitales-stream", message);
  }
  ```

- [ ] **3.2** `VitalSignsMessage.java`:
  ```java
  public class VitalSignsMessage {
      private String pacienteId;
      private String pacienteNombre;
      private int frecuenciaCardiaca;
      private int presionSistolica;
      private int presionDiastolica;
      private double temperatura;
      private int saturacionOxigeno;
      private LocalDateTime timestamp;
  }
  ```

- [ ] **3.3** `KafkaProducerConfig.java`:
  - Bootstrap servers: kafka1:9092,kafka2:9093,kafka3:9094
  - Key serializer: StringSerializer
  - Value serializer: JsonSerializer

- [ ] **3.4** Endpoints REST:
  - `POST /api/v1/stream/start` â†’ Iniciar generaciÃ³n
  - `POST /api/v1/stream/stop` â†’ Detener generaciÃ³n
  - `GET /api/v1/stream/stats` â†’ EstadÃ­sticas

**Entregable:** Microservicio que publica mensajes cada segundo

---

### âœ… TAREA 4: Desarrollar Productor 2 - Alert Processor (20 puntos)

**DescripciÃ³n:** Consume signos vitales, detecta anomalÃ­as, publica alertas

- [ ] **4.1** `VitalSignsConsumer.java`:
  ```java
  @KafkaListener(topics = "signos-vitales-stream", groupId = "alert-processor-group")
  public void consume(VitalSignsMessage message) {
      if (hasAnomalies(message)) {
          AlertMessage alert = createAlert(message);
          alertProducer.send("alertas-medicas", alert);
      }
  }
  ```

- [ ] **4.2** `AlertProcessor.java`:
  - LÃ³gica de detecciÃ³n de anomalÃ­as
  - Rangos mÃ©dicos normales
  - CÃ¡lculo de severidad

- [ ] **4.3** `AlertProducer.java`:
  - Publicar alertas a tÃ³pico `alertas-medicas`

**Entregable:** Microservicio que procesa stream y genera alertas

---

### âœ… TAREA 5: Desarrollar Consumidor 1 - Database Saver (20 puntos)

**DescripciÃ³n:** Consume ambos tÃ³picos y guarda en Oracle Cloud

- [ ] **5.1** `MultiTopicConsumer.java`:
  ```java
  @KafkaListener(topics = {"signos-vitales-stream", "alertas-medicas"})
  public void consumeMultiple(ConsumerRecord<String, String> record) {
      if (record.topic().equals("signos-vitales-stream")) {
          saveVitalSigns(record.value());
      } else {
          saveAlert(record.value());
      }
  }
  ```

- [ ] **5.2** Crear tablas en Oracle:
  ```sql
  CREATE TABLE SIGNOS_VITALES_KAFKA (
      id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      paciente_id VARCHAR2(50),
      frecuencia_cardiaca NUMBER,
      temperatura NUMBER(4,2),
      timestamp TIMESTAMP,
      kafka_partition NUMBER,
      kafka_offset NUMBER
  );

  CREATE TABLE ALERTAS_KAFKA (
      id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      paciente_id VARCHAR2(50),
      tipo_alerta VARCHAR2(100),
      severidad VARCHAR2(20),
      timestamp TIMESTAMP
  );
  ```

- [ ] **5.3** Configurar Oracle Wallet
- [ ] **5.4** Spring Data JPA repositories

**Entregable:** Microservicio que persiste datos en Oracle

---

### âœ… TAREA 6: Desarrollar Consumidor 2 - Summary Generator (20 puntos)

**DescripciÃ³n:** Genera resÃºmenes diarios del sistema

- [ ] **6.1** `SummaryConsumer.java`:
  - Consume ambos tÃ³picos
  - Agrega datos por dÃ­a
  - Calcula estadÃ­sticas

- [ ] **6.2** Tabla Oracle:
  ```sql
  CREATE TABLE RESUMEN_DIARIO_KAFKA (
      id NUMBER GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
      fecha DATE,
      total_pacientes NUMBER,
      total_mediciones NUMBER,
      total_alertas NUMBER,
      promedio_frecuencia_cardiaca NUMBER(5,2),
      promedio_temperatura NUMBER(4,2),
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
  );
  ```

- [ ] **6.3** Endpoint para ver resumen:
  - `GET /api/v1/summary/daily/{fecha}`

**Entregable:** Microservicio que genera resÃºmenes diarios

---

### âœ… TAREA 7: Video de PresentaciÃ³n (10 puntos)

**Requisitos:**
- âœ… DuraciÃ³n: 5-10 minutos
- âœ… Mostrar despliegue en cloud (opcional: Azure)
- âœ… Mostrar Kafka UI en funcionamiento
- âœ… Demostrar publicaciÃ³n y consumo de mensajes
- âœ… Mostrar datos en Oracle Cloud
- âœ… Explicar arquitectura y flujo de datos

**Puntos a cubrir:**
1. IntroducciÃ³n al sistema VitalWatch con Kafka
2. Mostrar cluster Kafka (7 contenedores)
3. Kafka UI: TÃ³picos, particiones, mensajes
4. Productor 1: Stream generando datos cada segundo
5. Productor 2: Procesando y generando alertas
6. Consumidores: Guardando en Oracle
7. Query en Oracle mostrando datos
8. Conclusiones

---

## ğŸ”§ DEPENDENCIAS MAVEN

### Para todos los microservicios:

```xml
<dependencies>
    <!-- Spring Boot -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-web</artifactId>
    </dependency>

    <!-- Spring Kafka -->
    <dependency>
        <groupId>org.springframework.kafka</groupId>
        <artifactId>spring-kafka</artifactId>
    </dependency>

    <!-- Spring Data JPA (solo consumidores que guardan en BD) -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-jpa</artifactId>
    </dependency>

    <!-- Oracle JDBC -->
    <dependency>
        <groupId>com.oracle.database.jdbc</groupId>
        <artifactId>ojdbc8</artifactId>
        <version>23.3.0.23.09</version>
    </dependency>

    <!-- Lombok -->
    <dependency>
        <groupId>org.projectlombok</groupId>
        <artifactId>lombok</artifactId>
        <optional>true</optional>
    </dependency>

    <!-- Jackson para JSON -->
    <dependency>
        <groupId>com.fasterxml.jackson.core</groupId>
        <artifactId>jackson-databind</artifactId>
    </dependency>
</dependencies>
```

---

## ğŸ“Š DIFERENCIAS: RABBITMQ vs KAFKA

| CaracterÃ­stica | RabbitMQ (Semana 6) | Kafka (Semana 8) |
|----------------|---------------------|------------------|
| **Tipo** | Message Queue | Streaming Platform |
| **Modelo** | Push (broker envÃ­a) | Pull (consumer solicita) |
| **Persistencia** | Temporal | Permanente (log) |
| **Ordenamiento** | Por cola | Por particiÃ³n |
| **Escalabilidad** | Vertical | Horizontal |
| **Caso de uso** | Tasks, jobs | Streaming, eventos |
| **ConfiguraciÃ³n** | 1 broker simple | Cluster (3 brokers + ZK) |
| **UI** | Management Plugin | Kafka UI |
| **Puerto** | 5672, 15672 | 9092, 8080 (UI) |

---

## â±ï¸ CRONOGRAMA RECOMENDADO

### **DÃ­a 1: Cluster Kafka**
- [ ] Configurar docker-compose-kafka.yml
- [ ] Levantar 7 contenedores
- [ ] Crear 2 tÃ³picos
- [ ] Verificar en Kafka UI

### **DÃ­a 2: Productores**
- [ ] Desarrollar Producer 1 (Stream Generator)
- [ ] Desarrollar Producer 2 (Alert Processor)
- [ ] Probar publicaciÃ³n de mensajes

### **DÃ­a 3: Consumidores**
- [ ] Desarrollar Consumer 1 (Database Saver)
- [ ] Desarrollar Consumer 2 (Summary Generator)
- [ ] Crear tablas en Oracle
- [ ] Probar persistencia

### **DÃ­a 4: IntegraciÃ³n y Pruebas**
- [ ] IntegraciÃ³n completa
- [ ] Pruebas end-to-end
- [ ] DocumentaciÃ³n

### **DÃ­a 5: Video y Entrega**
- [ ] Grabar video de presentaciÃ³n
- [ ] Comprimir proyecto
- [ ] Subir a GitHub
- [ ] Entregar

---

## ğŸ¯ CRITERIOS DE EVALUACIÃ“N (100 puntos)

| # | Criterio | Puntos | Estado |
|---|----------|--------|--------|
| 1 | Uso de Git/GitHub | 10 | â¬œ |
| 2 | Configurar cluster Kafka | 20 | â¬œ |
| 3 | Configurar 2 tÃ³picos y publicar | 20 | â¬œ |
| 4 | 2 microservicios consumidores | 20 | â¬œ |
| 5 | 2 microservicios productores | 20 | â¬œ |
| 6 | Video presentaciÃ³n | 10 | â¬œ |
| **TOTAL** | | **100** | |

---

## ğŸš€ COMANDOS RÃPIDOS

### **Levantar Cluster Kafka:**
```bash
docker-compose -f docker-compose-kafka.yml up -d
```

### **Ver logs:**
```bash
docker-compose -f docker-compose-kafka.yml logs -f kafka1
```

### **Listar tÃ³picos:**
```bash
docker exec -it kafka1 kafka-topics.sh --list --bootstrap-server localhost:9092
```

### **Consumir mensajes (debug):**
```bash
docker exec -it kafka1 kafka-console-consumer.sh \
  --topic signos-vitales-stream \
  --bootstrap-server localhost:9092 \
  --from-beginning
```

### **Ver grupos de consumidores:**
```bash
docker exec -it kafka1 kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --list
```

---

## ğŸ“š RECURSOS ÃšTILES

- **Apache Kafka Docs:** https://kafka.apache.org/documentation/
- **Spring Kafka:** https://spring.io/projects/spring-kafka
- **Kafka UI:** https://github.com/provectus/kafka-ui
- **Docker Compose Kafka:** https://github.com/wurstmeister/kafka-docker

---

## âœ… CHECKLIST FINAL

Antes de entregar, verificar:

- [ ] Cluster Kafka con 7 contenedores funcionando
- [ ] 2 tÃ³picos creados y visibles en Kafka UI
- [ ] Productor 1 generando mensajes cada 1 segundo
- [ ] Productor 2 procesando y generando alertas
- [ ] Consumidor 1 guardando en Oracle
- [ ] Consumidor 2 generando resÃºmenes
- [ ] Datos visibles en Oracle Cloud
- [ ] ColecciÃ³n Postman con pruebas
- [ ] Video de presentaciÃ³n (5-10 min)
- [ ] CÃ³digo subido a GitHub
- [ ] Proyecto comprimido (.zip)
- [ ] DocumentaciÃ³n completa

---

**Creado:** Febrero 2026
**VersiÃ³n:** 1.0
**Autor:** Sistema de PlanificaciÃ³n VitalWatch
