# üé• VitalWatch - Gui√≥n de Presentaci√≥n Kafka

**Duraci√≥n:** 5-10 minutos  
**Participantes:** 2 personas  
**Tema:** Sistema de Streaming en Tiempo Real con Apache Kafka

---

## üë• Roles

- **Presentador 1 (P1):** L√≠der t√©cnico - Explicaciones arquitectura y flujo
- **Presentador 2 (P2):** DevOps - Demostraciones pr√°cticas y monitoreo

---

## üé¨ INTRODUCCI√ìN (30 segundos)

**P1:** Hola a todos. Hoy presentaremos la evoluci√≥n de VitalWatch hacia un sistema de streaming en tiempo real usando Apache Kafka. Este sistema permite monitorear signos vitales de pacientes hospitalarios con procesamiento continuo y alta disponibilidad.

**P2:** Correcto. Pasamos de un modelo de mensajer√≠a tradicional con RabbitMQ a una arquitectura de event streaming que nos permite procesar hasta 86,400 mediciones diarias con garant√≠as de orden y la capacidad de reprocessar datos hist√≥ricos.

---

## üìä ARQUITECTURA DEL SISTEMA (1 minuto)

**P1:** Nuestra arquitectura Kafka consta de tres capas principales. En la base tenemos un cluster de 3 brokers Kafka con 3 nodos Zookeeper para alta disponibilidad. Esto nos garantiza que el sistema siga operando incluso si un broker falla.

**P2:** Sobre esta infraestructura, tenemos 2 t√≥picos principales: "signos-vitales-stream" que recibe las mediciones continuas, y "alertas-medicas" que contiene las alertas detectadas. Ambos t√≥picos tienen 3 particiones y un factor de replicaci√≥n de 2, lo que significa que cada mensaje se guarda en 2 brokers diferentes.

**P1:** Y en la capa de aplicaci√≥n tenemos 4 microservicios: dos productores y dos consumidores. El primer productor genera signos vitales cada 1 segundo simulando 5 pacientes en UCI. El segundo productor consume este stream, detecta anomal√≠as m√©dicas y publica alertas. Los consumidores se encargan de persistir todo en Oracle Cloud y generar res√∫menes diarios.

---

## üöÄ DEMOSTRACI√ìN 1: INICIAR CLUSTER KAFKA (1.5 minutos)

**P2:** Vamos a iniciar el cluster. *[Compartir pantalla - Terminal]*

```bash
./start-kafka-cluster.sh
```

**P2:** Como pueden ver, el script est√° levantando los 3 Zookeepers primero, luego los 3 brokers Kafka, y finalmente Kafka UI. Este proceso toma aproximadamente 1 minuto.

**P1:** Mientras esperamos, es importante destacar que Kafka es un sistema distribuido dise√±ado para manejar millones de mensajes por segundo. A diferencia de RabbitMQ donde los mensajes se eliminan despu√©s de consumirse, en Kafka los mensajes se persisten por 7 d√≠as en nuestro caso, permitiendo que m√∫ltiples consumidores lean el mismo stream.

**P2:** *[Cluster iniciado]* Perfecto. Ahora vamos a crear los t√≥picos.

```bash
./create-kafka-topics.sh
```

**P2:** Este script crea los dos t√≥picos: "signos-vitales-stream" con retenci√≥n de 7 d√≠as para el stream continuo, y "alertas-medicas" con retenci√≥n de 30 d√≠as porque las alertas son cr√≠ticas y pueden necesitarse para auditor√≠a.

---

## üåê DEMOSTRACI√ìN 2: KAFKA UI (1 minuto)

**P2:** Ahora abramos Kafka UI en el navegador. *[Abrir http://localhost:8080]*

**P2:** Aqu√≠ podemos ver el estado completo del cluster. *[Navegar a Brokers]* Tenemos 3 brokers activos. *[Navegar a Topics]* Y aqu√≠ est√°n nuestros dos t√≥picos con sus 3 particiones cada uno.

**P1:** Kafka UI es una herramienta esencial para monitoreo en producci√≥n. Nos permite ver en tiempo real el throughput, los consumer groups activos, el lag de procesamiento, y hasta inspeccionar mensajes individuales para debugging.

---

## üîÑ DEMOSTRACI√ìN 3: INICIAR MICROSERVICIOS (2 minutos)

**P2:** Ahora iniciemos los microservicios. *[Terminal]*

```bash
docker-compose -f docker-compose-kafka.yml up -d
```

**P2:** Esto levanta los 4 microservicios conectados al cluster Kafka. Esperemos unos segundos mientras arrancan...

```bash
docker-compose -f docker-compose-kafka.yml ps
```

**P2:** Perfecto, todos los servicios est√°n "running". Ahora vamos a iniciar el stream de signos vitales. *[Abrir Postman]*

**P2:** Aqu√≠ tengo la colecci√≥n de Postman con todos los endpoints. Primero verificamos el health del Stream Generator.

```
GET http://localhost:8081/api/v1/stream/health
```

**P1:** *[Mostrar respuesta JSON]* Como ven, el servicio est√° "UP" y listo. Este microservicio tiene un scheduler interno que genera signos vitales cada 1 segundo, pero empieza pausado para que tengamos control total.

**P2:** Ahora lo iniciamos.

```
POST http://localhost:8081/api/v1/stream/start
```

**P2:** *[Mostrar respuesta]* Excelente, el stream est√° "RUNNING". Volvamos a Kafka UI para ver los mensajes llegando.

---

## üìà DEMOSTRACI√ìN 4: MENSAJES EN TIEMPO REAL (1.5 minutos)

**P2:** *[Volver a Kafka UI - Topics - signos-vitales-stream - Messages]*

**P2:** ¬°Ah√≠ est√°n! Vean c√≥mo los mensajes est√°n llegando continuamente. Cada mensaje contiene los signos vitales completos de un paciente: frecuencia card√≠aca, presi√≥n arterial, temperatura, saturaci√≥n de ox√≠geno y frecuencia respiratoria.

**P1:** Noten que los mensajes se distribuyen autom√°ticamente entre las 3 particiones. Kafka usa el "pacienteId" como key, lo que garantiza que todos los mensajes de un mismo paciente vayan siempre a la misma partici√≥n. Esto es crucial para mantener el orden de los eventos por paciente.

**P2:** Ahora miremos el segundo t√≥pico de alertas. *[Navegar a alertas-medicas]*

**P2:** Aqu√≠ vemos las alertas que el Alert Processor est√° generando autom√°ticamente. Aproximadamente el 15% de las mediciones tienen alguna anomal√≠a, as√≠ que deber√≠amos ver alertas cada 6-7 segundos.

**P1:** *[Expandir un mensaje de alerta]* Cada alerta incluye el detalle completo de las anomal√≠as detectadas, la severidad calculada, y los valores exactos que causaron la alerta. Por ejemplo, aqu√≠ vemos una alerta "CRITICA" porque la saturaci√≥n de ox√≠geno est√° en 88%, por debajo del rango normal de 95-100%.

---

## üìä DEMOSTRACI√ìN 5: ESTAD√çSTICAS Y MONITOREO (1.5 minutos)

**P2:** Vamos a esperar 1 minuto para acumular datos y luego ver las estad√≠sticas. *[Esperar 1 minuto o usar time-lapse]*

**P2:** *[En Postman]* Consultamos las estad√≠sticas del Stream Generator:

```
GET http://localhost:8081/api/v1/stream/stats
```

**P1:** *[Mostrar respuesta]* Perfecto. En 1 minuto generamos 60 mensajes, que es exactamente la tasa esperada de 1 mensaje por segundo. El sistema est√° configurado para generar 3,600 mensajes por hora, lo que equivale a 86,400 mensajes por d√≠a.

**P2:** Ahora veamos las estad√≠sticas del Alert Processor:

```
GET http://localhost:8082/api/v1/processor/stats
```

**P1:** *[Mostrar respuesta]* Interesante. De 60 mensajes procesados, se generaron aproximadamente 9 alertas, lo que da una tasa del 15%. Esta tasa es configurable y refleja la probabilidad que programamos para generar valores anormales en el simulador.

---

## üíæ DEMOSTRACI√ìN 6: PERSISTENCIA EN ORACLE (1 minuto)

**P1:** Ahora verifiquemos que los datos se est√°n guardando correctamente en Oracle Cloud. *[Abrir Oracle SQL Developer o mostrar captura]*

```sql
SELECT 
    paciente_nombre,
    frecuencia_cardiaca,
    temperatura,
    saturacion_oxigeno,
    timestamp_medicion,
    kafka_partition,
    kafka_offset
FROM SIGNOS_VITALES_KAFKA
ORDER BY timestamp_medicion DESC
FETCH FIRST 20 ROWS ONLY;
```

**P1:** *[Mostrar resultados]* Perfecto. Aqu√≠ vemos las √∫ltimas 20 mediciones guardadas. Noten las columnas "kafka_partition" y "kafka_offset" - estas nos dan trazabilidad completa de d√≥nde vino cada mensaje en Kafka.

**P2:** Y ahora las alertas:

```sql
SELECT 
    alert_id,
    paciente_nombre,
    severidad,
    cantidad_anomalias,
    detected_at
FROM ALERTAS_KAFKA
ORDER BY detected_at DESC
FETCH FIRST 10 ROWS ONLY;
```

**P2:** *[Mostrar resultados]* Aqu√≠ est√°n las alertas m√°s recientes, incluyendo alertas CRITICAS que requieren atenci√≥n inmediata del personal m√©dico.

---

## üìà DEMOSTRACI√ìN 7: RESUMEN DIARIO (1 minuto)

**P1:** Uno de los beneficios de Kafka es que podemos tener m√∫ltiples consumidores procesando el mismo stream de datos de diferentes formas. Nuestro Summary Generator consume los mismos datos y genera res√∫menes agregados.

**P2:** *[En Postman]* Generemos un resumen del d√≠a actual:

```
POST http://localhost:8083/api/v1/summary/generate
```

**P1:** *[Mostrar respuesta]* Excelente. El resumen nos muestra estad√≠sticas agregadas: 5 pacientes monitoreados, las mediciones totales del d√≠a, las alertas generadas por severidad, y los promedios de todos los signos vitales.

**P2:** Este resumen se genera autom√°ticamente a medianoche usando un CRON scheduler, pero tambi√©n podemos generarlo bajo demanda para cualquier fecha espec√≠fica. Esto es perfecto para reportes gerenciales o an√°lisis retrospectivos.

---

## üîç DEMOSTRACI√ìN 8: CONSUMER GROUPS (1 minuto)

**P1:** Una caracter√≠stica clave de Kafka son los Consumer Groups. Vamos a verificar que no tengamos lag en el procesamiento.

**P2:** *[En terminal]*

```bash
docker exec -it vitalwatch-kafka1 kafka-consumer-groups \
  --bootstrap-server kafka1:9092 \
  --group alert-processor-group \
  --describe
```

**P1:** *[Mostrar output]* Aqu√≠ vemos el estado del consumer group "alert-processor-group". Las columnas m√°s importantes son "CURRENT-OFFSET" que indica hasta d√≥nde ha le√≠do el consumidor, y "LAG" que muestra cu√°ntos mensajes est√°n pendientes de procesar.

**P2:** En nuestro caso, el LAG es 0 en todas las particiones, lo que significa que estamos procesando los mensajes en tiempo real sin retraso. Si el LAG fuera alto, indicar√≠a que necesitamos escalar los consumidores.

---

## üìä ARQUITECTURA T√âCNICA: KAFKA VS RABBITMQ (1 minuto)

**P1:** Antes de concluir, quiero destacar por qu√© migramos de RabbitMQ a Kafka para este sistema.

**P1:** RabbitMQ es excelente para colas de tareas tradicionales con baja latencia, pero tiene limitaciones para streaming:
- Los mensajes se eliminan despu√©s de consumirse
- Throughput limitado a 20-50 mil mensajes por segundo
- No permite reprocessar eventos pasados

**P2:** Kafka, en cambio, est√° dise√±ado espec√≠ficamente para event streaming:
- Los mensajes se persisten por 7-30 d√≠as
- Throughput de hasta 1 mill√≥n de mensajes por segundo
- M√∫ltiples consumidores pueden leer el mismo stream
- Podemos reprocessar datos hist√≥ricos moviendo el offset
- Garantiza orden por partici√≥n

**P1:** Para nuestro caso de uso de monitoreo hospitalario, esto es cr√≠tico. Si necesitamos analizar el historial de signos vitales de un paciente, o si un nuevo servicio de machine learning necesita entrenar con datos pasados, simplemente creamos un nuevo consumer group y procesamos el stream desde el principio.

---

## üéØ PUNTOS CLAVE DEMOSTRADOS (30 segundos)

**P2:** Resumiendo lo que vimos:

**P2:**
1. ‚úÖ Cluster Kafka con 3 brokers para alta disponibilidad
2. ‚úÖ Stream Generator produciendo 1 mensaje por segundo de forma continua
3. ‚úÖ Alert Processor detectando anomal√≠as en tiempo real con tasa del 15%
4. ‚úÖ Database Saver persistiendo todo en Oracle Cloud sin lag
5. ‚úÖ Summary Generator generando res√∫menes autom√°ticos
6. ‚úÖ Kafka UI para monitoreo visual del sistema
7. ‚úÖ Consumer groups sin lag, procesando en tiempo real

**P1:**
8. ‚úÖ Trazabilidad completa con offset y partici√≥n
9. ‚úÖ Replicaci√≥n de datos (RF=2) para tolerancia a fallos
10. ‚úÖ API REST en todos los microservicios para integraci√≥n

---

## üöÄ DEPLOYMENT EN AZURE (30 segundos)

**P1:** Para el deployment en Azure, usamos Azure Container Apps para los microservicios, combinado con Azure Event Hubs que ofrece una API compatible con Kafka.

**P2:** Event Hubs nos da todas las ventajas de Kafka pero completamente gestionado por Azure: sin necesidad de administrar brokers, auto-scaling, backups autom√°ticos, y monitoreo integrado con Azure Monitor.

**P1:** El script de deployment `deploy-kafka-azure.sh` automatiza todo el proceso: crea el resource group, el Azure Container Registry, hace build y push de las 4 im√°genes Docker, y despliega cada microservicio con sus variables de entorno correspondientes.

---

## üìà RENDIMIENTO Y ESCALABILIDAD (30 segundos)

**P2:** En t√©rminos de rendimiento, nuestro sistema actual procesa:
- 1 mensaje por segundo por dise√±o (configurable)
- 60 mensajes por minuto
- 3,600 mensajes por hora
- 86,400 mediciones diarias m√°s 13,000 alertas

**P1:** Pero lo importante es que Kafka nos permite escalar esto f√°cilmente. Si necesitamos monitorear 100 pacientes en lugar de 5, simplemente:
1. Aumentamos la frecuencia del scheduler
2. Agregamos m√°s instancias del Alert Processor (Kafka distribuye autom√°ticamente)
3. Aumentamos la concurrencia de los consumidores

**P2:** Y gracias al particionamiento, el procesamiento es paralelo. Cada partici√≥n se puede consumir independientemente, lo que nos permite escalar horizontalmente agregando m√°s consumidores al grupo.

---

## üí° CASOS DE USO REALES (30 segundos)

**P1:** M√°s all√° de esta demo, este sistema tiene aplicaciones reales muy potentes:

**P1:**
1. **Alertas en tiempo real:** Un dashboard de enfermer√≠a puede consumir el t√≥pico de alertas y mostrar notificaciones instant√°neas cuando un paciente presenta signos cr√≠ticos.

2. **Machine Learning:** Un modelo de IA puede consumir el stream hist√≥rico para predecir deterioro del paciente horas antes de que ocurra.

3. **An√°lisis retrospectivo:** Si un paciente tuvo un evento m√©dico, podemos reprocessar su stream completo para an√°lisis post-mortem.

**P2:**
4. **Integraci√≥n con otros sistemas:** Cualquier sistema externo (registro m√©dico electr√≥nico, sistema de farmacia, etc.) puede consumir nuestro stream sin afectar el procesamiento existente.

---

## üé¨ CIERRE: RESULTADOS Y CONCLUSIONES (1 minuto)

**P1:** En conclusi√≥n, hemos implementado exitosamente un sistema de streaming en tiempo real con Apache Kafka que ofrece:

**P1:**
- ‚úÖ **Alta disponibilidad:** Cluster de 3 brokers con replicaci√≥n
- ‚úÖ **Procesamiento en tiempo real:** Latencia menor a 100ms
- ‚úÖ **Escalabilidad:** Arquitectura lista para crecer de 5 a 500 pacientes
- ‚úÖ **Trazabilidad:** Cada mensaje con su offset y partici√≥n
- ‚úÖ **Persistencia:** Retenci√≥n de 7-30 d√≠as para an√°lisis

**P2:**
- ‚úÖ **M√∫ltiples consumidores:** Base de datos, res√∫menes, y futuros servicios
- ‚úÖ **Reprocessamiento:** Capacidad de replay de eventos hist√≥ricos
- ‚úÖ **Monitoreo:** Kafka UI y m√©tricas en cada microservicio
- ‚úÖ **Cloud Native:** Despliegue en Azure con auto-scaling
- ‚úÖ **Producci√≥n ready:** Health checks, logging, error handling

**P1:** Lo m√°s importante es que este sistema no solo cumple con los requisitos actuales, sino que est√° dise√±ado para evolucionar. Podemos agregar nuevos consumidores sin tocar los existentes, escalar componentes independientemente, y mantener el historial completo de eventos para an√°lisis futuros.

**P2:** El c√≥digo est√° completamente documentado, con READMEs en cada microservicio, scripts de automatizaci√≥n, y una gu√≠a completa de pruebas. Todo est√° listo para producci√≥n.

**P1 & P2:** ¬°Gracias por su atenci√≥n! ¬øAlguna pregunta?

---

## üì∏ CHECKLIST PARA EL VIDEO

Antes de grabar, aseg√∫rate de tener:

- [ ] Cluster Kafka levantado y funcionando
- [ ] T√≥picos creados con 3 particiones cada uno
- [ ] Los 4 microservicios corriendo en Docker
- [ ] Stream iniciado y generando mensajes
- [ ] Kafka UI abierto en el navegador
- [ ] Postman con la colecci√≥n cargada
- [ ] Oracle SQL Developer con queries preparadas
- [ ] Terminal preparada con comandos
- [ ] Pantalla limpia, cerrar notificaciones
- [ ] Slides de arquitectura (opcional)

## ‚è±Ô∏è TIMING SUGERIDO

| Secci√≥n | Tiempo | Acumulado |
|---------|--------|-----------|
| Introducci√≥n | 0:30 | 0:30 |
| Arquitectura | 1:00 | 1:30 |
| Demo 1: Cluster | 1:30 | 3:00 |
| Demo 2: Kafka UI | 1:00 | 4:00 |
| Demo 3: Microservicios | 2:00 | 6:00 |
| Demo 4: Mensajes en tiempo real | 1:30 | 7:30 |
| Kafka vs RabbitMQ | 1:00 | 8:30 |
| Casos de uso | 0:30 | 9:00 |
| Cierre | 1:00 | 10:00 |

**Total:** 10 minutos

## üé§ CONSEJOS PARA LA GRABACI√ìN

1. **Preparaci√≥n:**
   - Ejecuta una prueba completa antes de grabar
   - Ten el sistema ya corriendo si es posible
   - Usa time-lapse para esperas largas

2. **Durante la grabaci√≥n:**
   - Habla con claridad y ritmo pausado
   - Muestra el mouse para que se vea qu√© est√°s haciendo
   - Pausa entre secciones para edici√≥n posterior

3. **Post-producci√≥n:**
   - Agrega zoom a √°reas importantes
   - Acelera las esperas (compilaci√≥n, docker pull)
   - Agrega m√∫sica de fondo suave
   - Subt√≠tulos opcionales para t√©rminos t√©cnicos

4. **Backup plan:**
   - Si algo falla en vivo, ten capturas de pantalla listas
   - Practica el gui√≥n al menos 2 veces
   - Ten un segundo terminal abierto por si acaso

¬°√âxito con tu presentaci√≥n! üöÄ
