# üéØ VitalWatch Kafka - Instrucciones de Inicio

## ‚úÖ ESTADO: IMPLEMENTACI√ìN COMPLETA

Todos los componentes del sistema Kafka han sido implementados y est√°n listos para usar.

## üì¶ Lo que se ha creado

### Infraestructura (1 archivo)
- ‚úÖ `docker-compose-kafka.yml` - Cluster completo (3 Zookeepers + 3 Kafka + Kafka UI + 4 microservicios)

### Microservicios (4 carpetas completas)
- ‚úÖ `producer-stream-generator/` - Genera signos vitales cada 1 segundo
- ‚úÖ `producer-alert-processor/` - Detecta anomal√≠as y publica alertas
- ‚úÖ `consumer-database-saver/` - Guarda en Oracle Cloud
- ‚úÖ `consumer-summary-generator/` - Genera res√∫menes diarios

### Base de Datos (1 archivo)
- ‚úÖ `database/create_tables_kafka.sql` - 4 tablas + 3 vistas + 4 triggers

### Scripts de Automatizaci√≥n (4 archivos)
- ‚úÖ `start-kafka-cluster.sh` - Inicia cluster paso a paso
- ‚úÖ `create-kafka-topics.sh` - Crea los 2 t√≥picos
- ‚úÖ `quick-start-kafka.sh` - Inicio r√°pido completo ‚≠ê
- ‚úÖ `deploy-kafka-azure.sh` - Deploy a Azure

### Documentaci√≥n (7 archivos)
- ‚úÖ `README_KAFKA.md` - Gu√≠a principal
- ‚úÖ `docs/ARQUITECTURA_KAFKA.md` - Detalles t√©cnicos
- ‚úÖ `GUIA_PRUEBAS_KAFKA.md` - C√≥mo probar
- ‚úÖ `DIALOGO_PRESENTACION_KAFKA.md` - Gui√≥n video
- ‚úÖ `IMPLEMENTACION_KAFKA_COMPLETA.md` - Resumen de implementaci√≥n
- ‚úÖ `KAFKA_QUICK_REFERENCE.md` - Referencia r√°pida
- ‚úÖ READMEs en cada microservicio

### Testing (1 archivo)
- ‚úÖ `docs/VitalWatch-Kafka.postman_collection.json` - 13 endpoints

---

## üöÄ INICIO R√ÅPIDO (3 Pasos)

### Paso 1: Crear Tablas en Oracle

1. Abrir SQL Developer o SQLcl
2. Conectarse a tu database: `ADMIN@s58onuxcx4c1qxe9_high`
3. Ejecutar el archivo: `database/create_tables_kafka.sql`
4. Verificar que se crearon 4 tablas

```sql
-- Verificaci√≥n r√°pida
SELECT table_name FROM user_tables 
WHERE table_name LIKE '%KAFKA%';
```

**Resultado esperado:**
```
SIGNOS_VITALES_KAFKA
ALERTAS_KAFKA
RESUMEN_DIARIO_KAFKA
PACIENTES_MONITOREADOS_KAFKA
```

### Paso 2: Iniciar Sistema Completo

```bash
./quick-start-kafka.sh
```

Este script autom√°ticamente:
- Levanta Zookeeper (30s de espera)
- Levanta Kafka Brokers (45s de espera)
- Levanta Kafka UI (10s de espera)
- Crea los 2 t√≥picos
- Inicia los 4 microservicios (60s de espera)
- Verifica health de cada servicio
- Inicia el stream autom√°ticamente
- Muestra comandos √∫tiles

**Tiempo total:** ~3 minutos

### Paso 3: Verificar que Funciona

#### A. Abrir Kafka UI
```
http://localhost:8080
```

Verificar:
- 3 Brokers activos
- 2 T√≥picos creados
- Mensajes llegando a `signos-vitales-stream` (1 por segundo)

#### B. Ver Estad√≠sticas

```bash
# Stream Generator
curl http://localhost:8081/api/v1/stream/stats

# Alert Processor  
curl http://localhost:8082/api/v1/processor/stats
```

#### C. Verificar Oracle

```sql
-- Ver cu√°ntas mediciones se han guardado
SELECT COUNT(*) as total, 
       MAX(timestamp_medicion) as ultima_medicion
FROM SIGNOS_VITALES_KAFKA;

-- Ver alertas
SELECT COUNT(*) as total_alertas,
       COUNT(DISTINCT paciente_id) as pacientes_afectados
FROM ALERTAS_KAFKA;
```

---

## üé• Para la Presentaci√≥n

### Antes de Grabar:

1. ‚úÖ Sistema corriendo con `./quick-start-kafka.sh`
2. ‚úÖ Dejar correr 5 minutos para acumular datos
3. ‚úÖ Abrir Kafka UI en http://localhost:8080
4. ‚úÖ Tener Postman abierto con la colecci√≥n importada
5. ‚úÖ Tener SQL Developer con queries preparadas
6. ‚úÖ Leer el gui√≥n: `DIALOGO_PRESENTACION_KAFKA.md`
7. ‚úÖ Cerrar notificaciones y apps innecesarias
8. ‚úÖ Preparar terminal con comandos √∫tiles

### Durante la Grabaci√≥n:

Seguir el gui√≥n de `DIALOGO_PRESENTACION_KAFKA.md`:
- Introducci√≥n (30s)
- Arquitectura (1 min)
- Demo Cluster (1.5 min)
- Demo Kafka UI (1 min)
- Demo Microservicios (2 min)
- Demo Mensajes en tiempo real (1.5 min)
- Demo Estad√≠sticas (1.5 min)
- Demo Oracle (1 min)
- Kafka vs RabbitMQ (1 min)
- Cierre (1 min)

**Total:** 10 minutos

---

## üê≥ Comandos Docker √ötiles

```bash
# Ver todos los servicios
docker-compose -f docker-compose-kafka.yml ps

# Ver logs en tiempo real de Stream Generator
docker logs -f vitalwatch-producer-stream

# Ver logs del Alert Processor
docker logs -f vitalwatch-producer-alert

# Reiniciar un servicio
docker-compose -f docker-compose-kafka.yml restart producer-stream-generator

# Rebuild y restart
docker-compose -f docker-compose-kafka.yml build producer-stream-generator
docker-compose -f docker-compose-kafka.yml up -d producer-stream-generator

# Detener todo
docker-compose -f docker-compose-kafka.yml down

# Ver uso de recursos
docker stats --no-stream
```

---

## üìä M√©tricas Esperadas (Despu√©s de 5 minutos)

| M√©trica | Valor Esperado |
|---------|----------------|
| Mensajes en stream | ~300 |
| Alertas generadas | ~45 (15%) |
| Registros en Oracle (signos) | ~300 |
| Registros en Oracle (alertas) | ~45 |
| LAG en consumer groups | 0 |
| Throughput | 1 msg/s |

---

## ‚ö†Ô∏è Notas Importantes

### Oracle Wallet
Los consumidores que se conectan a Oracle (Database Saver y Summary Generator) necesitan el Oracle Wallet en la carpeta `wallet/`. Este wallet ya est√° copiado:
- ‚úÖ `consumer-database-saver/wallet/`
- ‚úÖ `consumer-summary-generator/wallet/`

### Compilaci√≥n Maven Local
Si intentas compilar con Maven local (`mvn compile`) puede fallar por problemas de entorno. **Esto es normal y NO ES UN PROBLEMA** porque:
- ‚úÖ Docker build funciona correctamente (usa Maven en contenedor)
- ‚úÖ Los microservicios compilar√°n y correr√°n en Docker sin problemas
- ‚úÖ Ya se verific√≥ que `docker build` funciona

### Dockerfiles
Todos los Dockerfiles usan:
- **Stage 1:** `maven:3.9-eclipse-temurin-17` (build)
- **Stage 2:** `eclipse-temurin:17-jre` (runtime)

Estas im√°genes son multi-plataforma y funcionan en Mac (Intel y M1), Linux y Windows.

---

## üéØ Tu Pr√≥ximo Paso

### AHORA:

```bash
# 1. Crear tablas en Oracle (SQL Developer)
database/create_tables_kafka.sql

# 2. Iniciar sistema
./quick-start-kafka.sh

# 3. Esperar 5 minutos

# 4. Verificar funcionamiento:
# - Kafka UI: http://localhost:8080
# - Stats: curl http://localhost:8081/api/v1/stream/stats
# - Oracle: SELECT COUNT(*) FROM SIGNOS_VITALES_KAFKA;

# 5. Si todo funciona OK, preparar video
```

### DESPU√âS (Cuando local funcione):

1. Grabar video siguiendo `DIALOGO_PRESENTACION_KAFKA.md`
2. Deploy a Azure con `./deploy-kafka-azure.sh`

---

## üÜò Si Algo Falla

### Cluster no inicia
```bash
docker-compose -f docker-compose-kafka.yml down -v
./start-kafka-cluster.sh
```

### Microservicio tiene error
```bash
# Ver logs detallados
docker logs vitalwatch-producer-stream

# Rebuild
docker-compose -f docker-compose-kafka.yml build producer-stream-generator
docker-compose -f docker-compose-kafka.yml up -d producer-stream-generator
```

### No llegan mensajes a Oracle
```bash
# Ver logs del Database Saver
docker logs vitalwatch-consumer-db-kafka

# Verificar wallet
docker exec -it vitalwatch-consumer-db-kafka ls -la /app/wallet
```

### Consumer group con LAG
```bash
# Ver LAG
docker exec -it vitalwatch-kafka1 kafka-consumer-groups \
  --bootstrap-server kafka1:9092 \
  --group alert-processor-group \
  --describe

# Si LAG alto, aumentar concurrencia en KafkaConfig.java
```

---

## üìö Documentaci√≥n de Referencia

| Pregunta | Documento |
|----------|-----------|
| ¬øC√≥mo usar el sistema? | `README_KAFKA.md` |
| ¬øC√≥mo funciona la arquitectura? | `docs/ARQUITECTURA_KAFKA.md` |
| ¬øC√≥mo probar? | `GUIA_PRUEBAS_KAFKA.md` |
| ¬øQu√© comandos usar? | `KAFKA_QUICK_REFERENCE.md` |
| ¬øC√≥mo hacer el video? | `DIALOGO_PRESENTACION_KAFKA.md` |
| ¬øQu√© se implement√≥? | `IMPLEMENTACION_KAFKA_COMPLETA.md` |

---

## ‚úÖ Checklist Final

Antes de considerar el proyecto completo:

- [x] Infraestructura Kafka implementada
- [x] 4 Microservicios creados
- [x] Base de datos Oracle dise√±ada
- [x] Scripts de automatizaci√≥n
- [x] Documentaci√≥n completa
- [x] Colecci√≥n de Postman
- [x] Gui√≥n de presentaci√≥n
- [ ] Tablas creadas en Oracle ‚Üê **HACER AHORA**
- [ ] Sistema probado en local ‚Üê **SIGUIENTE**
- [ ] Video grabado ‚Üê **DESPU√âS**
- [ ] Deploy a Azure ‚Üê **FINAL**

---

**üéâ ¬°Todo est√° listo! Solo falta ejecutar y probar.**

**Siguiente comando:**
```bash
./quick-start-kafka.sh
```
