# ğŸ—ï¸ VitalWatch - Arquitectura Apache Kafka

DocumentaciÃ³n tÃ©cnica completa de la arquitectura de streaming con Apache Kafka.

## ğŸ“Š VisiÃ³n General

VitalWatch Kafka es un sistema de streaming en tiempo real para monitoreo de signos vitales hospitalarios, construido sobre Apache Kafka para garantizar:

- **Alta disponibilidad**: Cluster de 3 brokers con replicaciÃ³n
- **Alto throughput**: Hasta 1M mensajes/segundo
- **Procesamiento en tiempo real**: Latencia <100ms
- **Persistencia**: RetenciÃ³n configurable (7-30 dÃ­as)
- **Escalabilidad horizontal**: Particiones y consumer groups

## ğŸ¯ Componentes del Sistema

### 1. Cluster Kafka

#### Zookeeper Ensemble (3 nodos)
- **FunciÃ³n**: CoordinaciÃ³n del cluster, gestiÃ³n de configuraciÃ³n
- **Puerto**: 2181-2183
- **ReplicaciÃ³n**: Quorum de 3 nodos
- **ConfiguraciÃ³n**:
  - Tick time: 2000ms
  - Init limit: 5
  - Sync limit: 2

#### Kafka Brokers (3 nodos)
- **FunciÃ³n**: Almacenamiento y distribuciÃ³n de mensajes
- **Puertos internos**: 9092 (cada broker)
- **Puertos externos**: 19092, 19093, 19094
- **ConfiguraciÃ³n**:
  - Offsets topic replication: 2
  - Transaction log replication: 2
  - Auto create topics: enabled
  - Log retention: 168 horas

#### Kafka UI
- **FunciÃ³n**: Interfaz web para monitoreo
- **Puerto**: 8080
- **Features**:
  - VisualizaciÃ³n de tÃ³picos y mensajes
  - Monitoreo de consumer groups
  - EstadÃ­sticas de brokers
  - ConfiguraciÃ³n de tÃ³picos

### 2. TÃ³picos Kafka

#### signos-vitales-stream
```yaml
Nombre: signos-vitales-stream
Particiones: 3
Replication Factor: 2
Retention: 7 dÃ­as (604800000 ms)
Compression: snappy
Throughput: 1 mensaje/segundo
TamaÃ±o mensaje: ~500 bytes
Volumen diario: ~86,400 mensajes (~43 MB)
```

**Esquema del mensaje:**
```json
{
  "messageId": "uuid",
  "pacienteId": "P001",
  "pacienteNombre": "Juan PÃ©rez",
  "sala": "UCI-A",
  "cama": "101",
  "frecuenciaCardiaca": 75,
  "presionSistolica": 120,
  "presionDiastolica": 80,
  "temperatura": 36.6,
  "saturacionOxigeno": 98,
  "frecuenciaRespiratoria": 16,
  "deviceId": "DEVICE-001",
  "timestamp": "2026-02-13T10:30:45.123",
  "source": "STREAM_GENERATOR"
}
```

#### alertas-medicas
```yaml
Nombre: alertas-medicas
Particiones: 3
Replication Factor: 2
Retention: 30 dÃ­as (2592000000 ms)
Compression: snappy
Throughput: ~0.15 mensajes/segundo (15% anomalÃ­as)
TamaÃ±o mensaje: ~1-2 KB
Volumen diario: ~13,000 mensajes (~20 MB)
```

**Esquema del mensaje:**
```json
{
  "alertId": "ALERT-uuid",
  "pacienteId": "P001",
  "pacienteNombre": "Juan PÃ©rez",
  "sala": "UCI-A",
  "cama": "101",
  "tipoAlerta": "SIGNOS_VITALES_ANORMALES",
  "mensaje": "ALERTA MÃ‰DICA: Se detectaron 2 anomalÃ­as...",
  "severidad": "CRITICA",
  "frecuenciaCardiaca": 145,
  "presionSistolica": 165,
  "presionDiastolica": 95,
  "temperatura": 38.9,
  "saturacionOxigeno": 88,
  "frecuenciaRespiratoria": 26,
  "anomalias": [
    {
      "tipo": "CRITICA",
      "parametro": "Frecuencia CardÃ­aca",
      "valorActual": "145 lpm",
      "rangoNormal": "60-100 lpm"
    },
    {
      "tipo": "CRITICA",
      "parametro": "SaturaciÃ³n O2",
      "valorActual": "88 %",
      "rangoNormal": "95-100 %"
    }
  ],
  "cantidadAnomalias": 2,
  "deviceId": "DEVICE-001",
  "detectedAt": "2026-02-13T10:30:46.234",
  "source": "ALERT_PROCESSOR"
}
```

### 3. Microservicios

#### Producer 1: Stream Generator
```yaml
Nombre: producer-stream-generator
TecnologÃ­a: Spring Boot 3.2.1 + Spring Kafka
Puerto: 8081
FunciÃ³n: Generar stream continuo de signos vitales

CaracterÃ­sticas:
- Scheduler con fixedRate=1000ms (1 mensaje/segundo)
- GeneraciÃ³n aleatoria de signos vitales
- 15% probabilidad de generar anomalÃ­as
- 5 pacientes simulados
- API REST para control (start, stop, stats)
- KafkaTemplate asÃ­ncrono
- CompresiÃ³n snappy
- Acks=all para durabilidad

Endpoints:
- POST /api/v1/stream/start
- POST /api/v1/stream/stop
- GET /api/v1/stream/status
- POST /api/v1/stream/send-manual
- GET /api/v1/stream/stats
- GET /api/v1/stream/health

ConfiguraciÃ³n Kafka:
- Bootstrap servers: kafka1:9092,kafka2:9092,kafka3:9092
- TÃ³pico: signos-vitales-stream
- Key: pacienteId (para distribuciÃ³n en particiones)
- Serializer: JsonSerializer
- Acks: all
- Retries: 3
```

#### Producer 2: Alert Processor
```yaml
Nombre: producer-alert-processor
TecnologÃ­a: Spring Boot 3.2.1 + Spring Kafka
Puerto: 8082
FunciÃ³n: Consumir stream, detectar anomalÃ­as, publicar alertas

CaracterÃ­sticas:
- Consumer del tÃ³pico signos-vitales-stream
- Producer al tÃ³pico alertas-medicas
- DetecciÃ³n de anomalÃ­as en 6 parÃ¡metros vitales
- CÃ¡lculo de severidad (BAJA, MODERADA, ALTA, CRITICA)
- Procesamiento concurrente (2 listeners)
- API REST para estadÃ­sticas

Consumer:
- Group ID: alert-processor-group
- Concurrency: 2
- Auto offset reset: latest
- Max poll records: 10

Producer:
- TÃ³pico: alertas-medicas
- Key: pacienteId
- Acks: all

Rangos clÃ­nicos:
- FC: Normal 60-100, CrÃ­tico <40 o >120
- PA SistÃ³lica: Normal 90-120, CrÃ­tico <70 o >160
- Temperatura: Normal 36-37.5, CrÃ­tico <35 o >39.5
- SpO2: Normal 95-100, CrÃ­tico <90
```

#### Consumer 1: Database Saver
```yaml
Nombre: consumer-database-saver
TecnologÃ­a: Spring Boot 3.2.1 + JPA + Oracle JDBC
Puerto: Interno
FunciÃ³n: Persistir signos vitales y alertas en Oracle Cloud

CaracterÃ­sticas:
- 2 consumers independientes (vital signs + alerts)
- Procesamiento concurrente (3 listeners vital signs, 2 alerts)
- Spring Data JPA + Hibernate
- ConexiÃ³n TLS a Oracle Cloud
- Oracle Wallet para autenticaciÃ³n
- HikariCP connection pool
- Idempotencia (evita duplicados)

Consumers:
1. Vital Signs Consumer
   - Group ID: db-saver-vital-signs-group
   - Concurrency: 3
   - Max poll records: 100
   
2. Alerts Consumer
   - Group ID: db-saver-alerts-group
   - Concurrency: 2
   - VerificaciÃ³n de duplicados por alertId

Base de datos:
- Oracle Autonomous Database
- Connection pool: 10 max, 5 min idle
- Tablas: SIGNOS_VITALES_KAFKA, ALERTAS_KAFKA
```

#### Consumer 2: Summary Generator
```yaml
Nombre: consumer-summary-generator
TecnologÃ­a: Spring Boot 3.2.1 + JPA + Spring Scheduler
Puerto: 8083
FunciÃ³n: Generar resÃºmenes diarios agregados

CaracterÃ­sticas:
- Consultas SQL agregadas sobre Oracle
- Scheduler CRON para resÃºmenes automÃ¡ticos
- API REST para generaciÃ³n bajo demanda
- CÃ¡lculo de estadÃ­sticas completas

Tareas programadas:
1. Resumen diario (medianoche)
   - CRON: 0 0 0 * * ?
   - Genera resumen del dÃ­a anterior
   
2. ActualizaciÃ³n continua (cada 15 min)
   - CRON: 0 */15 * * * ?
   - Actualiza resumen del dÃ­a actual

Endpoints:
- POST /api/v1/summary/generate
- GET /api/v1/summary/daily/{fecha}
- GET /api/v1/summary/all
- GET /api/v1/summary/health

EstadÃ­sticas:
- Total pacientes monitoreados
- Total mediciones y alertas
- Promedios de signos vitales
- Valores mÃ¡ximos y mÃ­nimos
- Alertas por severidad
```

### 4. Base de Datos Oracle Cloud

#### SIGNOS_VITALES_KAFKA
```sql
Columnas principales:
- id (PK, auto-increment)
- kafka_topic, kafka_partition, kafka_offset (trazabilidad)
- paciente_id, paciente_nombre, sala, cama
- frecuencia_cardiaca, presion_sistolica, presion_diastolica
- temperatura, saturacion_oxigeno, frecuencia_respiratoria
- device_id, timestamp_medicion
- Constraint: UNIQUE(kafka_topic, kafka_partition, kafka_offset)

Ãndices:
- idx_sv_kafka_paciente (paciente_id, timestamp DESC)
- idx_sv_kafka_timestamp (timestamp DESC)
- idx_sv_kafka_sala (sala, timestamp DESC)
- idx_sv_kafka_offset (partition, offset)
```

#### ALERTAS_KAFKA
```sql
Columnas principales:
- id (PK)
- alert_id (UNIQUE)
- kafka_topic, kafka_partition, kafka_offset
- paciente_id, paciente_nombre, sala, cama
- tipo_alerta, mensaje, severidad
- signos vitales completos
- anomalias (JSON)
- cantidad_anomalias
- estado (ACTIVA, EN_REVISION, RESUELTA, DESCARTADA)
- detected_at, created_at, updated_at

Ãndices:
- idx_alertas_kafka_paciente
- idx_alertas_kafka_severidad
- idx_alertas_kafka_estado
- idx_alertas_kafka_alert_id
```

#### RESUMEN_DIARIO_KAFKA
```sql
Columnas principales:
- id (PK)
- fecha (UNIQUE)
- total_pacientes_monitoreados
- total_mediciones, mediciones_por_hora
- total_alertas por severidad
- promedios de todos los signos vitales
- valores mÃ¡ximos y mÃ­nimos
- mensajes_procesados por tÃ³pico
- timestamps de creaciÃ³n y actualizaciÃ³n
```

#### PACIENTES_MONITOREADOS_KAFKA
```sql
Columnas principales:
- id (PK)
- paciente_id (UNIQUE)
- paciente_nombre, sala, cama
- device_id
- estado (ACTIVO, INACTIVO, DADO_DE_ALTA)
- total_mediciones, ultima_medicion
- total_alertas, ultima_alerta
- fecha_ingreso, fecha_alta

Triggers:
- Auto-actualizaciÃ³n al recibir mediciones
- Auto-actualizaciÃ³n al recibir alertas
```

## ğŸ”„ Flujo de Procesamiento Detallado

### Fase 1: GeneraciÃ³n de Stream
```
1. Spring Scheduler (@Scheduled fixedRate=1000)
   â†“
2. VitalSignsGeneratorService.generateRandomVitalSigns()
   - Selecciona paciente aleatorio
   - Genera valores con 85% normales / 15% anormales
   â†“
3. VitalSignsStreamProducer.publishVitalSigns()
   - Key: pacienteId
   - Value: VitalSignsMessage (JSON)
   - Topic: signos-vitales-stream
   â†“
4. Kafka Broker recibe y distribuye por particiones
   - Hash(pacienteId) â†’ ParticiÃ³n
   - Replica en 2 brokers (RF=2)
```

### Fase 2: DetecciÃ³n de Alertas
```
1. VitalSignsStreamConsumer (@KafkaListener)
   - Consume de signos-vitales-stream
   - Group: alert-processor-group
   - Concurrency: 2
   â†“
2. AnomalyDetectionService.detectAnomalies()
   - Verifica 6 parÃ¡metros vitales
   - Compara con rangos clÃ­nicos
   - Construye lista de anomalÃ­as
   â†“
3. Si hay anomalÃ­as:
   - Calcula severidad
   - Construye mensaje de alerta
   â†“
4. AlertProducer.publishAlert()
   - Key: pacienteId
   - Value: AlertMessage (JSON)
   - Topic: alertas-medicas
```

### Fase 3: Persistencia en Oracle
```
1. Dos consumidores independientes:

   A. VitalSignsKafkaConsumer
      - Group: db-saver-vital-signs-group
      - Topic: signos-vitales-stream
      - Concurrency: 3
      â†“
      - Deserializa JSON a Map
      - Mapea a entidad SignosVitalesKafka
      - repository.save() â†’ Oracle
      - Trigger actualiza PACIENTES_MONITOREADOS_KAFKA
   
   B. AlertsKafkaConsumer
      - Group: db-saver-alerts-group
      - Topic: alertas-medicas
      - Concurrency: 2
      â†“
      - Deserializa JSON
      - Verifica duplicado por alertId
      - Mapea a entidad AlertaKafka
      - Serializa anomalÃ­as a JSON
      - repository.save() â†’ Oracle
```

### Fase 4: GeneraciÃ³n de ResÃºmenes
```
1. DailySummaryScheduler
   
   A. Resumen diario (medianoche)
      - CRON: 0 0 0 * * ?
      - Fecha: dÃ­a anterior
      â†“
   
   B. ActualizaciÃ³n continua (cada 15 min)
      - CRON: 0 */15 * * * ?
      - Fecha: dÃ­a actual
      â†“
      
2. SummaryService.generateDailySummary()
   - Query SQL agregada sobre SIGNOS_VITALES_KAFKA
   - Query SQL agregada sobre ALERTAS_KAFKA
   - Construye ResumenDiarioKafka
   - Upsert en tabla RESUMEN_DIARIO_KAFKA
```

## ğŸ“ˆ DistribuciÃ³n de Datos

### Particionamiento
```
Key: pacienteId
Hash Function: murmur2

Ejemplo con 5 pacientes y 3 particiones:
- P001 â†’ hash â†’ ParticiÃ³n 0
- P002 â†’ hash â†’ ParticiÃ³n 1
- P003 â†’ hash â†’ ParticiÃ³n 2
- P004 â†’ hash â†’ ParticiÃ³n 0
- P005 â†’ hash â†’ ParticiÃ³n 1

Beneficios:
âœ… Mensajes del mismo paciente van a la misma particiÃ³n
âœ… Orden garantizado por paciente
âœ… Procesamiento paralelo entre pacientes
```

### ReplicaciÃ³n
```
Replication Factor = 2

Topic: signos-vitales-stream
- ParticiÃ³n 0: kafka1 (leader), kafka2 (follower)
- ParticiÃ³n 1: kafka2 (leader), kafka3 (follower)
- ParticiÃ³n 2: kafka3 (leader), kafka1 (follower)

Ventajas:
âœ… Alta disponibilidad (1 broker puede fallar)
âœ… Sin pÃ©rdida de datos
âœ… Failover automÃ¡tico
```

### Consumer Groups
```
1. alert-processor-group
   - 1 instancia del Alert Processor
   - Consume de 3 particiones
   - Concurrency: 2 threads

2. db-saver-vital-signs-group
   - 1 instancia del Database Saver
   - Consume de 3 particiones
   - Concurrency: 3 threads

3. db-saver-alerts-group
   - 1 instancia del Database Saver
   - Consume de 3 particiones
   - Concurrency: 2 threads

4. summary-generator-group
   - 1 instancia del Summary Generator
   - No consume mensajes (solo queries SQL)

Beneficios:
âœ… Procesamiento independiente por grupo
âœ… Cada grupo mantiene su propio offset
âœ… Posibilidad de reprocessar datos
```

## ğŸ” Seguridad

### Oracle Cloud Connection
```yaml
Protocolo: TLS (tcps://)
Puerto: 1521
AutenticaciÃ³n: Oracle Wallet
  - cwallet.sso
  - ewallet.p12
  - tnsnames.ora
  - sqlnet.ora
Trust Store: /app/wallet/truststore.jks
```

### Kafka Security
```yaml
Protocolo: PLAINTEXT (desarrollo)
ProducciÃ³n recomendada:
  - SSL/TLS encryption
  - SASL authentication
  - ACLs por tÃ³pico
  - Zookeeper authentication
```

## ğŸ“Š Monitoreo y Observabilidad

### MÃ©tricas de Kafka
```
Broker Level:
- Messages in per second
- Bytes in per second
- Under-replicated partitions
- Offline partitions

Topic Level:
- Messages per second
- Bytes per second
- Partition count
- Replication status

Consumer Level:
- Lag (mensajes pendientes)
- Commit rate
- Fetch rate
```

### MÃ©tricas de Microservicios
```
Stream Generator:
- totalMessagesSent
- messagesPerMinute
- streamEnabled

Alert Processor:
- messagesProcessed
- alertsGenerated
- alertRate

Database Saver:
- messagesSaved (vital signs)
- alertsSaved
- database connection pool

Acceso via:
- Spring Actuator: /actuator/metrics
- Logs estructurados
- Application-specific endpoints
```

## ğŸš€ Despliegue

### Local (Docker Compose)
```bash
# 1. Iniciar cluster
./start-kafka-cluster.sh

# 2. Crear tÃ³picos
./create-kafka-topics.sh

# 3. Iniciar microservicios
docker-compose -f docker-compose-kafka.yml up -d

# 4. Verificar
docker-compose -f docker-compose-kafka.yml ps
```

### Azure (Container Apps + Event Hubs)
```bash
# 1. Crear Event Hubs namespace (compatible con Kafka)
az eventhubs namespace create \
  --name vitalwatch-kafka \
  --resource-group rg-vitalwatch-kafka \
  --location southcentralus \
  --sku Standard

# 2. Crear event hubs (equivalente a tÃ³picos)
az eventhubs eventhub create \
  --name signos-vitales-stream \
  --namespace-name vitalwatch-kafka \
  --partition-count 3

# 3. Desplegar microservicios
./deploy-kafka-azure.sh
```

## ğŸ”„ Kafka vs RabbitMQ - ComparaciÃ³n TÃ©cnica

| Aspecto | RabbitMQ | Apache Kafka |
|---------|----------|--------------|
| **Arquitectura** | Message Broker (pull/push) | Distributed Log (pull) |
| **Modelo** | Queues + Exchanges | Topics + Partitions |
| **Persistencia** | Opcional, hasta consumo | Persistente, configurable |
| **Orden** | Por cola | Por particiÃ³n |
| **Reprocessamiento** | No (destrucciÃ³n mensaje) | SÃ­ (offset management) |
| **Throughput** | 20K-50K msg/s | 100K-1M msg/s |
| **Latencia** | 1-5ms | 10-100ms |
| **Escalabilidad** | Vertical (cluster limitado) | Horizontal (particiones) |
| **RetenciÃ³n** | No (mensaje se elimina) | SÃ­ (dÃ­as/semanas) |
| **Consumer Groups** | No | SÃ­ (mÃºltiples consumidores) |
| **ReplicaciÃ³n** | Mirroring | Nativa (RF) |
| **Casos de uso** | Task queues, RPC | Event sourcing, streaming |

### Â¿CuÃ¡ndo usar Kafka?
âœ… Alto volumen de datos (>10K msg/s)  
âœ… Necesidad de reprocessar datos  
âœ… Event sourcing o audit log  
âœ… Streaming analytics  
âœ… MÃºltiples consumidores del mismo stream  
âœ… RetenciÃ³n de datos histÃ³ricos  

### Â¿CuÃ¡ndo usar RabbitMQ?
âœ… Baja latencia crÃ­tica (<1ms)  
âœ… Routing complejo (topic exchanges)  
âœ… Task queues tradicionales  
âœ… Volumen moderado (<10K msg/s)  
âœ… Prioridad de mensajes  
âœ… RPC patterns  

## ğŸ“š Conceptos Avanzados

### Offset Management
```
Cada consumidor mantiene su offset (posiciÃ³n de lectura):

ParticiÃ³n 0: [msg0, msg1, msg2, msg3, msg4, msg5, ...]
                                    â†‘
                              offset = 3

Ventajas:
- Reprocessamiento desde cualquier offset
- MÃºltiples consumer groups con offsets independientes
- Replay de eventos histÃ³ricos
```

### Exactly-Once Semantics
```
Para garantizar procesamiento exactly-once:

Producer:
- enable.idempotence=true
- acks=all
- retries>0

Consumer:
- Procesamiento idempotente
- Transacciones en base de datos
- VerificaciÃ³n de duplicados

En VitalWatch:
âœ… Alertas: VerificaciÃ³n por alertId
âœ… Signos vitales: Constraint UNIQUE en Kafka metadata
```

### CompresiÃ³n
```
Tipo: snappy

Ventajas:
âœ… Balance entre ratio y velocidad
âœ… Reduce bandwidth 2-4x
âœ… Reduce storage en disco

Alternativas:
- gzip: Mayor compresiÃ³n, mÃ¡s CPU
- lz4: MÃ¡s rÃ¡pido, menor compresiÃ³n
- zstd: Mejor balance (Kafka 2.1+)
```

## ğŸ“ Mejores PrÃ¡cticas Implementadas

### Producers
âœ… Acks=all para durabilidad  
âœ… Retries configurados  
âœ… Key para distribuciÃ³n  
âœ… CompresiÃ³n habilitada  
âœ… Batch y linger para throughput  

### Consumers
âœ… Consumer groups independientes  
âœ… Concurrencia adecuada  
âœ… Error handling robusto  
âœ… Offset management automÃ¡tico  
âœ… Idempotencia en procesamiento  

### Topics
âœ… Particiones mÃºltiples (paralelismo)  
âœ… Replication factor â‰¥ 2  
âœ… RetenciÃ³n apropiada al caso de uso  
âœ… CompresiÃ³n configurada  

### Operaciones
âœ… Health checks en todos los servicios  
âœ… Logging estructurado  
âœ… MÃ©tricas expuestas  
âœ… Scripts de automatizaciÃ³n  
âœ… DocumentaciÃ³n completa  

## ğŸ“– Referencias

- [Apache Kafka Docs](https://kafka.apache.org/documentation/)
- [Spring Kafka](https://spring.io/projects/spring-kafka)
- [Confluent Best Practices](https://docs.confluent.io/platform/current/installation/docker/config-reference.html)
- [Azure Event Hubs (Kafka)](https://docs.microsoft.com/azure/event-hubs/event-hubs-for-kafka-ecosystem-overview)
